"""
Markdown è§£æå™¨
è§£ææ–°é—»æ‘˜è¦ Markdown æ–‡ä»¶ï¼Œæå–æ–‡ç« ç»“æ„
"""

import re
from typing import List, Dict, Any
from dataclasses import dataclass
from loguru import logger


@dataclass
class Article:
    """æ–°é—»æ–‡ç« æ•°æ®ç»“æ„"""
    title: str              # æ–°é—»æ ‡é¢˜
    content: str            # æ­£æ–‡å†…å®¹
    category: str           # åˆ†ç±»ï¼ˆè´¢ç»ã€ç§‘æŠ€ç­‰ï¼‰
    source: str             # æ¥æºï¼ˆåå°”è¡—è§é—»ç­‰ï¼‰
    url: str                # åŸæ–‡é“¾æ¥
    char_count: int         # å­—ç¬¦æ•°


class MarkdownParser:
    """Markdown è§£æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è§£æå™¨"""
        # åŒ¹é… #### æ ‡é¢˜ï¼ˆæ–°é—»æ ‡é¢˜ï¼‰
        self.article_pattern = re.compile(r'^####\s+(\d+)\.\s+(.+)$', re.MULTILINE)
        # åŒ¹é… ### æ ‡é¢˜ï¼ˆæ–°é—»æºï¼‰
        self.source_pattern = re.compile(r'^###\s+ğŸ“°\s+(.+)$', re.MULTILINE)
        # åŒ¹é… ## æ ‡é¢˜ï¼ˆåˆ†ç±»ï¼‰
        self.category_pattern = re.compile(r'^##\s+(.+)$', re.MULTILINE)
        # åŒ¹é…é“¾æ¥
        self.url_pattern = re.compile(r'\*\*åŸæ–‡é“¾æ¥\*\*:\s+\[(.+?)\]\((.+?)\)')
    
    def parse_digest(self, markdown_path: str) -> List[Article]:
        """
        è§£ææ–°é—»æ‘˜è¦ Markdown æ–‡ä»¶
        
        Args:
            markdown_path: Markdown æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡ç« åˆ—è¡¨
        """
        logger.info(f"å¼€å§‹è§£æ Markdown æ–‡ä»¶: {markdown_path}")
        
        with open(markdown_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        articles = self.extract_articles(content)
        
        logger.success(f"è§£æå®Œæˆ: æå– {len(articles)} ç¯‡æ–‡ç« ")
        return articles
    
    def extract_articles(self, content: str) -> List[Article]:
        """
        æå–æ‰€æœ‰æ–°é—»æ–‡ç« 
        
        Args:
            content: Markdown å†…å®¹
            
        Returns:
            æ–‡ç« åˆ—è¡¨
        """
        articles = []
        
        # æŒ‰ ## åˆ†ç±»åˆ†å‰²
        category_sections = re.split(r'^## ', content, flags=re.MULTILINE)[1:]
        
        for category_section in category_sections:
            lines = category_section.split('\n')
            category = lines[0].strip()
            
            # è·³è¿‡ç›®å½•å’Œç»Ÿè®¡éƒ¨åˆ†
            if category in ['ğŸ“‘ ç›®å½•', 'ğŸ“Š é‡‡é›†ç»Ÿè®¡']:
                continue
            
            # æŒ‰ ### æ–°é—»æºåˆ†å‰²
            source_sections = re.split(r'^### ', category_section, flags=re.MULTILINE)[1:]
            
            for source_section in source_sections:
                source_lines = source_section.split('\n')
                source_name = source_lines[0].replace('ğŸ“° ', '').strip()
                
                # æŒ‰ #### æ–‡ç« æ ‡é¢˜åˆ†å‰²
                article_sections = re.split(r'^#### ', source_section, flags=re.MULTILINE)[1:]
                
                for article_section in article_sections:
                    article = self._parse_article(
                        article_section,
                        category=category,
                        source=source_name
                    )
                    if article:
                        articles.append(article)
        
        return articles
    
    def _parse_article(
        self,
        article_text: str,
        category: str,
        source: str
    ) -> Article:
        """
        è§£æå•ç¯‡æ–‡ç« 
        
        Args:
            article_text: æ–‡ç« æ–‡æœ¬
            category: åˆ†ç±»
            source: æ¥æº
            
        Returns:
            Article å¯¹è±¡æˆ– None
        """
        lines = article_text.split('\n')
        
        # æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œï¼‰
        title_line = lines[0].strip()
        # ç§»é™¤åºå·ï¼ˆå¦‚ "1. "ï¼‰
        title_match = re.match(r'^\d+\.\s+(.+)$', title_line)
        if title_match:
            title = title_match.group(1)
        else:
            title = title_line
        
        # æå– URL
        url = ""
        url_match = self.url_pattern.search(article_text)
        if url_match:
            url = url_match.group(2)
        
        # æå–æ­£æ–‡å†…å®¹
        content_parts = []
        in_content = False
        
        for line in lines[1:]:
            # è·³è¿‡ç©ºè¡Œå’Œåˆ†éš”ç¬¦
            if not line.strip() or line.strip() == '---':
                continue
            
            # è·³è¿‡é“¾æ¥è¡Œ
            if '**åŸæ–‡é“¾æ¥**' in line:
                continue
            
            # å¼€å§‹æ”¶é›†æ­£æ–‡
            if '**æ­£æ–‡å†…å®¹**' in line or '**æ‘˜è¦**' in line:
                in_content = True
                continue
            
            if in_content:
                # é‡åˆ°ä¸‹ä¸€ä¸ªæ ‡é¢˜æˆ–åˆ†éš”ç¬¦ï¼Œåœæ­¢
                if line.startswith('#') or line.strip() == '---':
                    break
                content_parts.append(line)
        
        content = '\n'.join(content_parts).strip()
        
        # å¦‚æœæ²¡æœ‰å†…å®¹ï¼Œè·³è¿‡
        if not content:
            return None
        
        return Article(
            title=title,
            content=content,
            category=category,
            source=source,
            url=url,
            char_count=len(title) + len(content)
        )
